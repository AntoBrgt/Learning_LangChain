{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9abadcf0",
   "metadata": {},
   "source": [
    "# Installation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a22246fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"gemma3\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad6dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "output = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fae3f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The most natural translation of \"I love programming\" in French is:\\n\\n**J\\'adore la programmation.**\\n\\nHere are a couple of other options, though \"J\\'adore la programmation\" is the most common:\\n\\n*   **J\\'aime la programmation beaucoup.** (I like programming a lot)\\n*   **Je suis passionné(e) par la programmation.** (I am passionate about programming - use \"passionnée\" if you are female)', additional_kwargs={}, response_metadata={'model': 'gemma3', 'created_at': '2025-07-29T13:12:35.0348173Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13941564200, 'load_duration': 259110800, 'prompt_eval_count': 31, 'prompt_eval_duration': 152162500, 'eval_count': 99, 'eval_duration': 13528221100, 'model_name': 'gemma3'}, id='run--05733b8a-3140-4d7b-ba8c-aa2191e804c1-0', usage_metadata={'input_tokens': 31, 'output_tokens': 99, 'total_tokens': 130})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb52b19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris!', additional_kwargs={}, response_metadata={'model': 'gemma3', 'created_at': '2025-07-29T13:14:37.445704Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1816914800, 'load_duration': 225639100, 'prompt_eval_count': 33, 'prompt_eval_duration': 1296829400, 'eval_count': 3, 'eval_duration': 293379100, 'model_name': 'gemma3'}, id='run--edae620a-8052-4d43-9783-9a616864e3ad-0', usage_metadata={'input_tokens': 33, 'output_tokens': 3, 'total_tokens': 36})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "system_msg = SystemMessage(\n",
    "'''You are a helpful assistant that responds to questions exclamation marks.'''\n",
    ")\n",
    "human_msg = HumanMessage('What is the capital of France?')\n",
    "llm.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d574e8",
   "metadata": {},
   "source": [
    "# Making prompt reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d9eb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"\"\"Answer the question context below. If the question cannot be answered using provided, answer with \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c83be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.invoke({\n",
    "\"context\": \"\"\"The most recent advancements in NLP are being Language Models (LLMs). These models outperform their counterparts and have become invaluable for developers applications with NLP capabilities. Developers can tap models through Hugging Face's `transformers` library, OpenAI and Cohere's offerings through the `openai` and libraries, respectively.\"\"\",\n",
    "\"question\": \"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "completion = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14951e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='OpenAI and Cohere.', additional_kwargs={}, response_metadata={'model': 'gemma3', 'created_at': '2025-07-29T13:19:05.9596777Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1453546000, 'load_duration': 357840000, 'prompt_eval_count': 112, 'prompt_eval_duration': 186058200, 'eval_count': 7, 'eval_duration': 907635900, 'model_name': 'gemma3'}, id='run--c2abcbeb-bc4c-4c58-8fdb-2df03acbe9cf-0', usage_metadata={'input_tokens': 112, 'output_tokens': 7, 'total_tokens': 119})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aee1067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "('system', '''Answer the question based on the context below. question cannot be answered using the information provided, \"I don\\'t know\".'''),\n",
    "('human', 'Context: {context}'),\n",
    "('human', 'Question: {question}'),\n",
    "])\n",
    "\n",
    "prompt = template.invoke({\n",
    "\"context\": \"\"\"The most recent advancements in NLP are being Language Models (LLMs). These models outperform their counterparts and have become invaluable for developers applications with NLP capabilities. Developers can tap models through Hugging Face's `transformers` library, OpenAI and Cohere's offerings through the `openai` and\n",
    "libraries, respectively.\"\"\",\n",
    "\"question\": \"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "completion = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05d33afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='OpenAI and Cohere.', additional_kwargs={}, response_metadata={'model': 'gemma3', 'created_at': '2025-07-29T13:21:26.681658Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6631477500, 'load_duration': 257329500, 'prompt_eval_count': 114, 'prompt_eval_duration': 5474679600, 'eval_count': 7, 'eval_duration': 893611500, 'model_name': 'gemma3'}, id='run--d4b7fed4-43cc-4b5f-a4f4-84be9324d64f-0', usage_metadata={'input_tokens': 114, 'output_tokens': 7, 'total_tokens': 121})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b2765",
   "metadata": {},
   "source": [
    "# JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ea1475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"They weigh the same.\",\n",
      "  \"justification\": \"This is a classic trick question! Both the bricks and the feathers weigh one pound. The trick lies in our tendency to associate bricks with being heavy and feathers with being light. However, the question specifies that they both weigh a pound.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user's question along with justification answer.'''\n",
    "    answer: str\n",
    "    '''The answer to the user's question'''\n",
    "    justification: str\n",
    "    '''Justification for the answer'''\n",
    "    \n",
    "llm = ChatOllama(\n",
    "model = \"gemma3\",\n",
    "temperature = 0.8,\n",
    "num_predict = 100,\n",
    ")\n",
    "\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "result = structured_llm.invoke(\"What weighs more, a pound of bricks or a pound of feathers?\")\n",
    "print(result.json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4798f0",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "924a28a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'cherry']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "items = parser.invoke(\"apple, banana, cherry\")\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effca58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down which model providers are offering Large Language Models (LLMs) as of today, October 26, 2023. This is a rapidly evolving space, so things can change quickly! Here's a categorized list:\n",
      "\n",
      "**1. Major Cloud Providers (Offering Their Own Models & APIs):**\n",
      "\n",
      "* **Google AI (formerly Google Cloud AI):**\n",
      "    * **PaLM 2:** Their flagship model, known for strong reasoning and\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# the building blocks\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "('system', 'You are a helpful assistant.'),\n",
    "('human', '{question}'),\n",
    "])\n",
    "\n",
    "chatbot = template | llm\n",
    "\n",
    "response = chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54eb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in llm.stream(prompt):\n",
    "        yield token\n",
    "    for part in chatbot.stream({\"question\": \"Which model providers offer LLMs?\"}):\n",
    "        print(part.content)\n",
    "\n",
    "chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149a462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Okay, let’s break down which model providers are offering Large Language Models (LLMs) as of today, November 2, 2023. This is a rapidly evolving space, so things can change quickly! Here’s a categorized list:\\n\\n**1. Major Cloud Providers (Offering APIs & Managed Services):**\\n\\n* **Google (Google AI / Vertex AI):** Google offers a range of models through its Vertex AI platform, including:\\n    * **PaLM', additional_kwargs={}, response_metadata={'model': 'gemma3', 'created_at': '2025-07-29T13:38:19.1002828Z', 'done': True, 'done_reason': 'length', 'total_duration': 16948676400, 'load_duration': 240610100, 'prompt_eval_count': 27, 'prompt_eval_duration': 169979600, 'eval_count': 100, 'eval_duration': 16534999800, 'model_name': 'gemma3'}, id='run--4aa91de5-064b-47bb-a600-1ec86122e75a-0', usage_metadata={'input_tokens': 27, 'output_tokens': 100, 'total_tokens': 127})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = template | llm\n",
    "await chatbot.ainvoke({\n",
    "\"question\": \"Which model providers offer LLMs?\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
